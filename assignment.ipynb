{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "HÜSEYİN GÜLŞİN - 2020*******"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6A9LPtw3XgYG"
      },
      "source": [
        "Before looking for **CART** decision tree algorithm implementation here, you need to understand fundamentals of CART algorithm.(https://github.com/milaan9/Python_Decision_Tree_and_Random_Forest/blob/main/002_Decision_Tree_PlayGolf_CART.ipynb)[more detail about CART algorithm]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xdygDXQd54Mo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('trainSet.csv')\n",
        "test_df = pd.read_csv('testSet.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uroXZVLIPZPK"
      },
      "source": [
        "We opened our csv data sets above. But there are some categorical variables in some colums. We can translate these categorial variables to numeric with Label Encder.(alternative: one-hot encoding)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OBKxIogSPXmR"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LbtDIg4ZkV2"
      },
      "source": [
        "Why **fit_transform** is used for the train while **transform** is for the test?\n",
        "\n",
        "Because during preprocessing, train data learns and returns transformed data with fit_transform. To apply for test data same parameters that learned with fit_transform, you should use transform.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ny92ZIhRPfjq"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "\n",
        "for col in ['A1', 'A4', 'A5', 'A6', 'A7', 'A9', 'A10', 'A12', 'A13']:\n",
        "    train_df[col] = le.fit_transform(train_df[col].astype(str))\n",
        "    test_df[col] = le.transform(test_df[col].astype(str))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLbUfyuElUTe"
      },
      "source": [
        "We need to create a Node to calculate all the leaves.\n",
        "Nodes will decide left or right looking for the feature and its threshold. If low than the threshold then the left node otherwise right node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaURgO8plauj"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "    def __init__(self, data, target):\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "        self.data = data\n",
        "        self.target = target\n",
        "        self.feature = None\n",
        "        self.threshold = None\n",
        "        self.prediction = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgaDQTMjqBz_"
      },
      "source": [
        "Gini Impurity is an important part of the during searching for leaves. It is a statistical measure to calculate homogeneity. The algorithm splits the dataset with the lowest index of Gini and threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giXY6P6RrNxa"
      },
      "outputs": [],
      "source": [
        "def gini_impurity(groups, classes):\n",
        "    n_instances = sum([len(group) for group in groups])\n",
        "    gini = 0.0\n",
        "    for group in groups:\n",
        "        \n",
        "        size = len(group)\n",
        "        \n",
        "        if size == 0:\n",
        "            continue\n",
        "        score = 0.0\n",
        "        for class_val in classes:\n",
        "            p = [row[-1] for row in group].count(class_val) / size\n",
        "            score += p * p\n",
        "        gini += (1.0 - score) * (size / n_instances)\n",
        "    return gini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwE1mlOdwPQn"
      },
      "source": [
        "We are listing left and right nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zoQllNHtsS_"
      },
      "outputs": [],
      "source": [
        "def test_split(index, value, data):\n",
        "    left, right = list(), list()\n",
        "    for row in data:\n",
        "        if row[index] < value:\n",
        "            left.append(row)\n",
        "        else:\n",
        "            right.append(row)\n",
        "    return left, right"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6MII1UQ3dqY"
      },
      "source": [
        "Time to train data on Node. max_depth and min_samples parameters are required for Pre-pruning. This function works recursively on node.left and node.right."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyD4B4Ktts8y"
      },
      "outputs": [],
      "source": [
        "# Pre-pruning is the process of stopping the tree-building process early before it reaches maximum depth by setting some stopping criteria. In my code it is max_depth and min_samples parameters.\n",
        "\n",
        "def get_split(data, max_depth, min_samples, depth=1):\n",
        "    class_values = list(set(row[-1] for row in data))\n",
        "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
        "    for index in range(len(data[0])-1):\n",
        "        for row in data:\n",
        "            groups = test_split(index, row[index], data)\n",
        "            \n",
        "            gini = gini_impurity(groups, class_values)\n",
        "            if gini < b_score:\n",
        "                b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
        "    node = Node(data, class_values)\n",
        "    if b_score == 0:\n",
        "        node.prediction = max(set([row[-1] for row in data]), key=[row[-1] for row in data].count)\n",
        "        return node\n",
        "    if depth >= max_depth or len(data) <= min_samples:\n",
        "        node.prediction = max(set([row[-1] for row in data]), key=[row[-1] for row in data].count)\n",
        "        return node\n",
        "    node.feature = b_index\n",
        "    node.threshold = b_value\n",
        "    node.left = get_split(b_groups[0], max_depth, min_samples, depth+1)\n",
        "    node.right = get_split(b_groups[1], max_depth, min_samples, depth+1)\n",
        "    return node\n",
        "\n",
        "\n",
        "\n",
        "root = get_split(train_df.values, 5, 5)  # Maximum depth: 5, Minimum number of samples: 5"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9xhsVtQ9L77Z"
      },
      "source": [
        "After training, we need to see our results. In order to evaluate tp, tn, fp, and fn, you should use the following steps; we are sending the last form of the node to predict function. Then we are storing the predictions that come from test data. Finally, evaluate with prediction and actual values. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkvQtsM7t1DA"
      },
      "outputs": [],
      "source": [
        "def predict(node, row):\n",
        "    if node.prediction is not None:\n",
        "        return node.prediction\n",
        "    if row[node.feature] < node.threshold:\n",
        "        return predict(node.left, row)\n",
        "    else:\n",
        "        return predict(node.right, row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqGrhwXzuLj6"
      },
      "outputs": [],
      "source": [
        "def test_tree(root, test_data):\n",
        "    predictions = []\n",
        "    for i in range(len(test_data)):\n",
        "        result = predict(root, test_data.iloc[i])\n",
        "        predictions.append(result)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyW2vqSDuOgf"
      },
      "outputs": [],
      "source": [
        "def evaluate(predictions, actual):\n",
        "    tp, tn, fp, fn = 0, 0, 0, 0\n",
        "    for i in range(len(predictions)):   \n",
        "        if predictions[i] == actual[i]:\n",
        "            if predictions[i] == \"good\":\n",
        "                tp += 1\n",
        "            else:\n",
        "                tn += 1\n",
        "        else:\n",
        "            if predictions[i] == \"good\":\n",
        "                fp += 1\n",
        "            else:\n",
        "                fn += 1\n",
        "    accuracy = (tp + tn) / len(predictions)\n",
        "    tpr = tp / (tp + fn)\n",
        "    tnr = tn / (tn + fp)\n",
        "    return accuracy, tpr, tnr, tp, tn\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sHa_5bIqNb4w"
      },
      "source": [
        "For instance, test_predictions is equal to stored predictions that come from test_tree function, train_actual is equal to train data which comes from the class column and lastly sending this data to evaluate function to obtain the following results: \n",
        "train_accuracy, train_tpr, train_tnr, train_tp, train_tn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9WIm5TZuQqy"
      },
      "outputs": [],
      "source": [
        "train_predictions = test_tree(root, train_df)\n",
        "train_actual = train_df['class']\n",
        "train_accuracy, train_tpr, train_tnr, train_tp, train_tn = evaluate(train_predictions, train_actual)\n",
        "\n",
        "print('Eğitim (Train) sonucu:')\n",
        "print('Accuracy:', train_accuracy)\n",
        "print('True Positive Rate:', train_tpr)\n",
        "print('True Negative Rate:', train_tnr)\n",
        "print('True Positive Count:', train_tp)\n",
        "print('True Negative Count:', train_tn)\n",
        "\n",
        "test_predictions = test_tree(root, test_df)\n",
        "test_actual = test_df['class']\n",
        "test_accuracy, test_tpr, test_tnr, test_tp, test_tn = evaluate(test_predictions, test_actual)\n",
        "\n",
        "print('\\nSınama (Test) sonucu:')\n",
        "print('Accuracy:', test_accuracy)\n",
        "print('True Positive Rate:', test_tpr)\n",
        "print('True Negative Rate:', test_tnr)\n",
        "print('True Positive Count:', test_tp)\n",
        "print('True Negative Count:', test_tn)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
